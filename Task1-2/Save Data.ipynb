{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e4accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "ATTEMPTS = [0, 1, 2, 3, 4]\n",
    "SECONDS = 1\n",
    "INPUT_SIZE = 4096 * SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97f2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the names of different samples\n",
    "\n",
    "train_sample_names = []\n",
    "test_splits_w = []\n",
    "test_splits_n = []\n",
    "\n",
    "for attempt in ATTEMPTS:\n",
    "    train_sample_names.append([])\n",
    "    test_splits_w.append([])\n",
    "    test_splits_n.append([])\n",
    "    with open(\"data/attempt%d/split_info_%d_sec_%d.txt\" % (attempt, SECONDS, attempt)) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            line = line.split(\": \")\n",
    "            if line[0] == \"gw_test_ids\":\n",
    "                test_splits_w[-1] += eval(line[1])\n",
    "            elif line[0] == \"noise_test_ids\":\n",
    "                test_splits_n[-1] += eval(line[1])\n",
    "            elif line[0] == \"noise_train_ids\":\n",
    "                train_sample_names[-1] += eval(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a69b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load waves\n",
    "import pandas as pd\n",
    "\n",
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for attempt in ATTEMPTS:\n",
    "    all_samples = pd.read_csv(\"data/attempt%d/test_%d_sec_%d.csv\" % (attempt, SECONDS, attempt)).values.tolist()\n",
    "    all_samples += pd.read_csv(\"data/attempt%d/train_%d_sec_%d_1.csv\" % (attempt, SECONDS, attempt)).values.tolist()\n",
    "    all_samples += pd.read_csv(\"data/attempt%d/train_%d_sec_%d_2.csv\" % (attempt, SECONDS, attempt)).values.tolist()\n",
    "    \n",
    "    train_splits.append([s[3:] for s in all_samples if s[1] in train_sample_names[attempt]])\n",
    "    \n",
    "    test_splits.append([])\n",
    "    test_splits[-1] += [(s[3:], (0, 1)) for s in all_samples if s[1] in test_splits_w[attempt]]\n",
    "    test_splits[-1] += [(s[3:], (1, 0)) for s in all_samples if s[1] in test_splits_n[attempt]]\n",
    "    \n",
    "assert len(train_splits[0][0]) == 4096 * SECONDS and len(test_splits[0][0][0]) == 4096 * SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76dbeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to big pickle file\n",
    "from pickle import dump\n",
    "\n",
    "dump(([[s[0] for s in t] for t in test_splits], [[s[1] for s in t] for t in test_splits]), open(\"data/test_%d_%d.pickle\" % (INPUT_SIZE, SECONDS), \"wb+\"))\n",
    "dump(train_splits, open(\"data/train_%d_%d.pickle\" % (INPUT_SIZE, SECONDS), \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d2155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

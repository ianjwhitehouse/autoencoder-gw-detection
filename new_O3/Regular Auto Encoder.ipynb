{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f98d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240207151303\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "import string\n",
    "from random import choices, choice\n",
    "from datetime import datetime\n",
    "\n",
    "INPUT_SIZE = [512, 1024, 2048, 4096]\n",
    "HIDDEN_LAYERS = [1, 2]\n",
    "HIDDEN_LAYER_DIVISOR = [2, 4, 8]\n",
    "Z_LAYER_DIVISOR = [4, 8, 16, 32]\n",
    "DROPOUT = [.1, .25, .5]\n",
    "LEARNING_RATE = [0.000001, 0.00001, 0.0001]\n",
    "BATCH_SIZE = [8, 16, 32]\n",
    "FOLLOWER = True\n",
    "\n",
    "DATA_SET = \"O3 Run\"\n",
    "TYPE = \"Vanilla AE\"\n",
    "TIME_LENGTH = 1\n",
    "DIFFERENCE_THRESHS = [.8 + 0.2 * i for i in range(25)]\n",
    "ATTEMPT = 0 # Set later, doesn't make a difference\n",
    "\n",
    "# New masking section\n",
    "MASKING = [True, False]\n",
    "MASK_SIZE = [.25, .5, .75]\n",
    "\n",
    "name = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "model_final_stats = {\"name\": name, \"dataset\": DATA_SET, \"type\": TYPE, \"len\": TIME_LENGTH}\n",
    "\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665d95ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2678682/2516016999.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Assign whether follower or not based on the previous models attempt\n",
    "import pandas as pd\n",
    "\n",
    "# Previous failed\n",
    "previous_failed = False\n",
    "\n",
    "try:\n",
    "    open(\"failed\", \"x\")\n",
    "except FileExistsError:\n",
    "    if FOLLOWER:\n",
    "        crash()\n",
    "    else:\n",
    "        previous_failed = True\n",
    "\n",
    "try:\n",
    "    previous_trials = pd.read_csv(\"ae_trials.csv\").to_dict(\"records\")\n",
    "    if len(previous_trials) % 2 == 1:\n",
    "        print(1)\n",
    "        FOLLOWER = True\n",
    "        ATTEMPT = previous_trials[-1][\"attempt\"]\n",
    "    elif previous_trials[-1][\"attempt\"] == 4:\n",
    "        print(2)\n",
    "        FOLLOWER = False\n",
    "        ATTEMPT = 0\n",
    "    else:\n",
    "        print(3)\n",
    "        FOLLOWER = True\n",
    "        ATTEMPT = previous_trials[-1][\"attempt\"] + 1\n",
    "    \n",
    "    if previous_failed:\n",
    "        print(\"Prev Failed\")\n",
    "        FOLLOWER = False\n",
    "        ATTEMPT = 0\n",
    "        \n",
    "        \n",
    "except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "    print(4)\n",
    "    FOLLOWER = False\n",
    "    ATTEMPT = 0\n",
    "\n",
    "model_final_stats[\"attempt\"] = ATTEMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d87bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '20240207151303', 'dataset': 'O3 Run', 'type': 'Vanilla AE', 'len': 1, 'attempt': 2, 'leader': 20240207071341, 'input_size': 4096, 'hidden_layers': 2, 'hidden_layers_divisor': 8, 'z_layer_divisor': 32, 'dropout': 0.25, 'learning_rate': 1e-06, 'batch_size': 32, 'masking': False, 'mask_size': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Pick hyperparameters\n",
    "hyper_params = {\n",
    "    \"input_size\": choice(INPUT_SIZE),\n",
    "    \"hidden_layers\": choice(HIDDEN_LAYERS),\n",
    "    \"hidden_layers_divisor\": choice(HIDDEN_LAYER_DIVISOR),\n",
    "    \"z_layer_divisor\": choice(Z_LAYER_DIVISOR),\n",
    "    \"dropout\": choice(DROPOUT),\n",
    "    \"learning_rate\": choice(LEARNING_RATE),\n",
    "    \"batch_size\": choice(BATCH_SIZE),\n",
    "    \"masking\": choice(MASKING),\n",
    "    \"mask_size\": choice(MASK_SIZE)\n",
    "}\n",
    "hyper_params[\"input_size\"] *= TIME_LENGTH\n",
    "hyper_params[\"hidden_layers_divisor\"] *= TIME_LENGTH\n",
    "hyper_params[\"z_layer_divisor\"] *= TIME_LENGTH\n",
    "model_final_stats[\"leader\"] = None\n",
    "\n",
    "if FOLLOWER:\n",
    "    previous_models = pd.read_csv(\"ae_trials.csv\", keep_default_na=False).to_dict(\"records\")\n",
    "    for model in previous_models[::-1]: # We want to find the original leader not a fake leader\n",
    "        if not model[\"leader\"]:\n",
    "            model_final_stats[\"leader\"] = model[\"name\"]\n",
    "            break\n",
    "    \n",
    "    for key in hyper_params.keys():\n",
    "        hyper_params[key] = model[key]\n",
    "\n",
    "model_final_stats.update(hyper_params)\n",
    "print(model_final_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541664c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from pickle import load\n",
    "from random import sample\n",
    "\n",
    "x_tests, y_tests = load(open(\"data/test_%d.pickle\" % hyper_params[\"input_size\"], \"rb\"))\n",
    "x_tests = [[x - 0.5 for x in sample] for sample in x_tests[ATTEMPT]]\n",
    "y_tests = y_tests[ATTEMPT]\n",
    "\n",
    "x_train = load(open(\"data/train_%d.pickle\" % hyper_params[\"input_size\"], \"rb\"))\n",
    "x_train = [[x - 0.5 for x in sample] for sample in x_train]\n",
    "\n",
    "# Mask x_tests and y_tests\n",
    "if hyper_params[\"masking\"]:\n",
    "    # print(int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"]), hyper_params[\"input_size\"])\n",
    "    # print(len(x_tests))\n",
    "    x_tests = [[x, [x[i] for i in sorted(sample(range(len(x)), int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"])))]] for x in x_tests]\n",
    "    x_train = [[x, [x[i] for i in sorted(sample(range(len(x)), int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"])))]] for x in x_train]\n",
    "\n",
    "x_tests, y_tests = [x_tests], [y_tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336ab493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 15:13:09.944700: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-07 15:13:09.982289: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-07 15:13:11.116947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 455)               1864135   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 455)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               58368     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18703815 (71.35 MB)\n",
      "Trainable params: 18703815 (71.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 15:13:12.536342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22260 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:18:00.0, compute capability: 8.9\n",
      "2024-02-07 15:13:12.536982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22453 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create encoder model\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "encoder = models.Sequential()\n",
    "\n",
    "if hyper_params[\"masking\"]:\n",
    "    encoder.add(layers.Input(shape=int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"])))\n",
    "else:\n",
    "    encoder.add(layers.Input(shape=hyper_params[\"input_size\"]))\n",
    "\n",
    "for i in range(hyper_params[\"hidden_layers\"]):\n",
    "    encoder.add(layers.Dense(hyper_params[\"input_size\"]//(hyper_params[\"hidden_layers_divisor\"] * i + 1), activation=\"elu\"))\n",
    "    encoder.add(layers.Dropout(hyper_params[\"dropout\"]))\n",
    "encoder.add(layers.Dense(hyper_params[\"input_size\"]//hyper_params[\"z_layer_divisor\"]))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9434c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 455)               58695     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 455)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              1867776   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18707783 (71.36 MB)\n",
      "Trainable params: 18707783 (71.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create decoder model\n",
    "\n",
    "decoder = models.Sequential()\n",
    "decoder.add(layers.Input(hyper_params[\"input_size\"]//hyper_params[\"z_layer_divisor\"]))\n",
    "for i in list(range(hyper_params[\"hidden_layers\"]))[::-1]:\n",
    "    decoder.add(layers.Dense(hyper_params[\"input_size\"]//(hyper_params[\"hidden_layers_divisor\"] * i + 1), activation=\"elu\"))\n",
    "    decoder.add(layers.Dropout(hyper_params[\"dropout\"]))\n",
    "decoder.add(layers.Dense(hyper_params[\"input_size\"]))\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5cbafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 128)               18703815  \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 4096)              18707783  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37411598 (142.71 MB)\n",
      "Trainable params: 37411598 (142.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create autoencoder model\n",
    "\n",
    "autoencoder = models.Sequential()\n",
    "\n",
    "if hyper_params[\"masking\"]:\n",
    "    autoencoder.add(layers.Input(shape=int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"])))\n",
    "else:\n",
    "    autoencoder.add(layers.Input(shape=hyper_params[\"input_size\"]))\n",
    "\n",
    "autoencoder.add(encoder)\n",
    "autoencoder.add(decoder)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f44aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 15:13:16.347934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-07 15:13:16.397672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xfa0ccf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-07 15:13:16.397718: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-02-07 15:13:16.397733: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-02-07 15:13:16.411672: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-07 15:13:16.448585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2024-02-07 15:13:16.563707: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-02-07 15:13:16.563731: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-02-07 15:13:16.589995: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 5s 11ms/step - loss: 0.0338 - val_loss: 0.0265\n",
      "Epoch 2/300\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0327 - val_loss: 0.0260\n",
      "Epoch 3/300\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0318 - val_loss: 0.0255\n",
      "Epoch 4/300\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0310 - val_loss: 0.0251\n",
      "Epoch 5/300\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0303 - val_loss: 0.0247\n",
      "Epoch 6/300\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0297 - val_loss: 0.0243\n",
      "Epoch 7/300\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.0291 - val_loss: 0.0239\n",
      "Epoch 8/300\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0286 - val_loss: 0.0236\n",
      "Epoch 9/300\n",
      " 15/282 [>.............................] - ETA: 2s - loss: 0.0284"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_train)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(x_train), hyper_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 24\u001b[0m     fit_run \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyper_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mae_saved/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[1;32m     34\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m fit_run\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model and save weights\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=hyper_params[\"learning_rate\"])\n",
    "autoencoder.compile(opt, loss=\"mse\")\n",
    "\n",
    "if hyper_params[\"masking\"]:\n",
    "    y_train = np.array([x[0] for x in x_train]).reshape(len(x_train), hyper_params[\"input_size\"])\n",
    "    x_train = np.array([x[1] for x in x_train]).reshape(len(x_train), int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"]))\n",
    "    \n",
    "    fit_run = autoencoder.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=300,\n",
    "        batch_size=hyper_params[\"batch_size\"],\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)], validation_split=0.1\n",
    "    )\n",
    "else:\n",
    "    x_train = np.array(x_train).reshape(len(x_train), hyper_params[\"input_size\"])\n",
    "    \n",
    "    fit_run = autoencoder.fit(\n",
    "        x_train,\n",
    "        x_train,\n",
    "        epochs=300,\n",
    "        batch_size=hyper_params[\"batch_size\"],\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)], validation_split=0.1\n",
    "    )\n",
    "\n",
    "\n",
    "autoencoder.save_weights(\"ae_saved/%s\" % name)\n",
    "final_loss = fit_run.history[\"val_loss\"][-1]\n",
    "\n",
    "ae_res = {\"gen_loss\": None, \"disc_loss\": None, \"val_loss\": fit_run.history[\"val_loss\"][-1], \"epochs\": len(fit_run.history[\"val_loss\"])}\n",
    "model_final_stats.update(ae_res)\n",
    "\n",
    "print(ae_res)\n",
    "plt.plot(range(len(fit_run.history[\"val_loss\"])), fit_run.history[\"val_loss\"])\n",
    "plt.title(\"Autoencoder Loss: %s, %s\" % (TYPE, name))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Loss (MSE)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf643d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits of z layers, run difference classifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from statistics import mean\n",
    "\n",
    "mse = MeanSquaredError()\n",
    "\n",
    "# Copied from latent layer classifiers\n",
    "def save_results(name, hyper_params, metrics, model_name):\n",
    "    try:\n",
    "        previous_trials = pd.read_csv(\"latent_trials.csv\").to_dict(\"records\")\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        previous_trials = []\n",
    "\n",
    "    model_final_stats = {\"Classifier\": name, \"Based on AE\": model_name}\n",
    "    model_final_stats.update(hyper_params)\n",
    "    \n",
    "    model_final_stats[\"precision\"] = metrics[0]\n",
    "    model_final_stats[\"recall\"] = metrics[1]\n",
    "    model_final_stats[\"f-score\"] = metrics[2]\n",
    "    \n",
    "    previous_trials.append(model_final_stats)\n",
    "    pd.DataFrame(previous_trials).to_csv(\"latent_trials.csv\", index=None)\n",
    "    \n",
    "    print(model_final_stats)\n",
    "\n",
    "for split, x_test, y_test in zip(range(len(x_tests)), x_tests, y_tests):\n",
    "\n",
    "    if hyper_params[\"masking\"]:\n",
    "        z_layers = encoder.predict(np.array([x[1] for x in x_test]).reshape(len(x_test), int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"])))\n",
    "    else:\n",
    "        z_layers = encoder.predict(np.array(x_test).reshape(len(x_test), hyper_params[\"input_size\"]))\n",
    "    \n",
    "    outputs = decoder.predict(z_layers).tolist()\n",
    "    print(y_test[0])\n",
    "    class_true = [[np.argmax(y)] for y in y_test]\n",
    "    \n",
    "    z_layers = [y + z.tolist() for z, y in zip(z_layers, class_true)]\n",
    "    pd.DataFrame(z_layers).to_pickle(\"z_layers/%s.pickle.gzip\" % (name))\n",
    "    print(\"Saved z-layers for %s\" % split)\n",
    "    \n",
    "    for i, sigma in enumerate(DIFFERENCE_THRESHS):\n",
    "        results = [[], []]\n",
    "        for y_pred, y_true, y_class in zip(outputs, x_test, class_true):\n",
    "            results[0].append(y_class)\n",
    "            results[1].append(1 if mse(y_pred, y_true[0]).numpy() > sigma * final_loss else 0)\n",
    "        save_results(\"ReconstructionThreshold\", {\"sigma\": sigma}, list(precision_recall_fscore_support(results[0], results[1], average=\"binary\"))[:3], name)\n",
    "    print(\"Done with split %s\" % split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eedf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot five graphs\n",
    "from random import shuffle\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc(\"font\", size=MEDIUM_SIZE)\n",
    "plt.rc(\"axes\", titlesize=MEDIUM_SIZE, labelsize=MEDIUM_SIZE)\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)\n",
    "\n",
    "tests_for_graph = [(x, y) for x, y in zip(x_tests[0], y_tests[0])]\n",
    "shuffle(tests_for_graph)\n",
    "\n",
    "for x, y in tests_for_graph[:10]:\n",
    "    if hyper_params[\"masking\"]:\n",
    "        encoded_x = encoder.predict(np.array(x[1]).reshape(1, int(hyper_params[\"input_size\"] * hyper_params[\"mask_size\"])))\n",
    "    else:\n",
    "        encoded_x = encoder.predict(np.array(x).reshape(1, hyper_params[\"input_size\"]))\n",
    "    \n",
    "    plt.hist(encoded_x.tolist()[0], bins=20)\n",
    "    plt.title(\"Encoding of a%s: %s, %s\" % (\"n Anomalous Signal\" if np.argmax(y) == 1 else \" Normal Signal\", TYPE, name))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if hyper_params[\"masking\"]:\n",
    "        plt.plot([(v - (0.5 * len(x[0])))/4.096 for v in range(len(x[0]))], x[0], label=\"Original Time Series\")\n",
    "        plt.plot([(v - (0.5 * len(x[0])))/4.096 for v in range(len(x[0]))], decoder.predict(encoded_x).tolist()[0], label=\"Reproduction Time Series\")\n",
    "    else:\n",
    "        plt.plot([(v - (0.5 * len(x)))/4.096 for v in range(len(x))], x, label=\"Original Time Series\")\n",
    "        plt.plot([(v - (0.5 * len(x)))/4.096 for v in range(len(x))], decoder.predict(encoded_x).tolist()[0], label=\"Reproduction Time Series\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Reproduction of a%s: %s, %s\" % (\"n Anomalous Signal\" if np.argmax(y) == 1 else \" Normal Signal\", TYPE, name))\n",
    "    plt.xlabel(\"Time (Milliseconds)\")\n",
    "    plt.ylabel(\"Strain\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to file\n",
    "\n",
    "try:\n",
    "    previous_trials = pd.read_csv(\"ae_trials.csv\").to_dict(\"records\")\n",
    "except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "    previous_trials = []\n",
    "\n",
    "previous_trials.append(model_final_stats)\n",
    "pd.DataFrame(previous_trials).to_csv(\"ae_trials.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7665680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Temp Lock\n",
    "import os\n",
    "\n",
    "os.remove(\"failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
